---
title: "Penguins ì¸ê³µì‹ ê²½ë§"
excerpt: "Penguins ë°ì´í„°ë¡œ ì¸ê³µì‹ ê²½ë§ êµ¬ì„±í•˜ê¸°"

categories:
  - Dev Log

tags:
  - ê°œë°œì¼ì§€
  - ì½”ë”©
  - keras
  - Neural Network

use_math: true

header:
  teaser: /assets/images/aib/artificial-intelligence-3685928_1920.png

last_modified_at: 2023-02-21
---


<br><br>


![image]({{ site.url }}{{ site.baseurl }}/assets/images/etc/penguin_png.png){: .align-center width="70%"}  


<br><br>


<br><br>


# Penguins, ì¸ê³µì‹ ê²½ë§ êµ¬ì„±  


<br><br>


## ë„ì…  
>Penguins ë°ì´í„°ë¡œ ì¸ê³µì‹ ê²½ë§ ë§Œë“¤ê¸°  
ì¸ê³µì‹ ê²½ë§ì„ ê³µë¶€í•˜ëŠ”MNISTë¥¼ ìì£¼ ì‚¬ìš©í•˜ê³¤ í•˜ì§€ë§Œ, MNISTì˜ indexëŠ” 60,000ê°œë¡œ ì‚¬ì´ì¦ˆê°€ í¬ê¸° ë•Œë¬¸ì— í•™ìŠµì— ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦°ë‹¤.  
ê·¸ë˜ì„œ ë°ì´í„° ì‚¬ì´ì¦ˆê°€ ì‘ê³  ê·€ì—¬ìš´ Penguins ë°ì´í„°ë¡œ ì¸ê³µì‹ ê²½ë§ì„ ì—°ìŠµí•˜ì


<br><br>


## ë°ì´í„° ì „ì²˜ë¦¬  

### ë°ì´í„° ì½ì–´ì˜¤ê¸°  

```python
# Data Load
penguins = sns.load_dataset('penguins')
print(f"ğŸ¬ Rows, Columns : {penguins.shape}")
# ğŸ¬ Rows, Columns : (344, 7)
```

- ë°ì´í„°ëŠ” Seabornì—ì„œ ë¶ˆëŸ¬ì™”ë‹¤.
- ë°ì´í„°ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì€ [Seaborn ë§í¬ ì°¸ì¡°](https://github.com/allisonhorst/palmerpenguins) í•´ì£¼ì„¸ìš”

<br>

### íŠ¹ì„±ê³µí•™

- íŠ¹ë³„í•œ íŠ¹ì„±ê³µí•™ì€ í•˜ì§€ ì•ŠìŒ
- sexê°€ ê²°ì¸¡ì¸ ê²½ìš° 3ìœ¼ë¡œ ëŒ€ì²´
- ë‹¤ë¥¸ íŠ¹ì„±ì€ í‰ê· ìœ¼ë¡œ ëŒ€ì²´

```python
penguins_species = {
    'Adelie' : 0,
    'Gentoo' : 1,
    'Chinstrap' : 2,
}
penguins['species'] = penguins['species'].map(penguins_species)

penguins_island = {
    'Biscoe' : 0,
    'Dream' : 1,
    'Torgersen' : 2,
}
penguins['island'] = penguins['island'].map(penguins_island)

penguins_sex = {
    'Male' : 0,
    'Female' : 1,
    np.nan : 3,
}
penguins['sex'] = penguins['sex'].map(penguins_sex)

# NaN = Fill with Mean
for idx, col in enumerate(penguins.columns):
  penguins[col].fillna(penguins[col].mean(), inplace=True)
```

<br>

### ë°ì´í„° ë¶„í• 

```python
test_size = 0.2
x_train, x_test, y_train, y_test = train_test_split(penguins[features], penguins[target], test_size=test_size, random_state=rand_seed)
print(f'âœ¨Train Shape : {x_train.shape} / {y_train.shape}\nğŸ‰ Test Shape : {x_test.shape} / {y_test.shape}')
#âœ¨Train Shape : (275, 6) / (275, 1)
#ğŸ‰ Test Shape : (69, 6) / (69, 1)
```

<br>

### ì •ê·œí™”(Normalization)

```python
x_train = (x_train - np.min(x_train, axis='index')) / (np.max(x_train, axis='index') - np.min(x_train, axis='index'))
x_test  = ( x_test - np.min( x_test, axis='index')) / (np.max( x_test, axis='index') - np.min( x_test, axis='index'))
```


<br><br>


## íƒìƒ‰ì  ë°ì´í„° ë¶„ì„

### Seaborn ì˜ ë°ì´í„° ì†Œê°œë¡œ ëŒ€ì²´

![image](https://github.com/allisonhorst/palmerpenguins/raw/main/man/figures/culmen_depth.png){: .align-center width="60%"}  


![image](https://seaborn.pydata.org/_images/introduction_29_0.png){: .align-center width="80%"}  


<br><br>


## ëª¨ë¸ë§

### ê¸°ì¤€ëª¨ë¸ : Logistic Regression

- ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ëª¨ë¸ì„ ê¸°ì¤€ëª¨ë¸ë¡œ í•˜ì!

```python
log_model = LogisticRegression()
log_model.fit(x_train, y_train)
log_score = print_accuracy(log_model)
log_CM, fig = draw_CM(log_model)
# Train Accuracy : 0.978, Test Accuracy : 0.971
```

- ê¸°ë³¸ëª¨ë¸ ì •í™•ë„ê°€ ë¬´ë ¤ 97.1% ğŸ˜³ (í°ì¼ì´ë‹¤...)
- ë³´í†µì€ ê¸°ì¤€ëª¨ë¸ ì´ìƒì„ ëª©í‘œë¡œ í•˜ì§€ë§Œ ì˜¤ëŠ˜ì€ ê¸°ì¤€ëª¨ë¸ ë§Œí¼ì´ë¼ë„ ë‹¬ì„±í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ì

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/logit_cm.png){: .align-center width="60%"}  

<br>

### ê¸°ë³¸ ì¸ê³µì‹ ê²½ë§ : ì€ë‹‰ì¸µ 0ê°œ

- ê°€ì¥ ê¸°ë³¸ì ì¸ ì¸ê³µì‹ ê²½ë§ì„ ë§Œë“¤ì–´ë³´ì

```python
model1 = tf.keras.Sequential([
    Dense(3, activation='softmax'),
    ])

model1.compile(metrics=['accuracy']
               , optimizer='adam'
               , loss='sparse_categorical_crossentropy'
               )

results1 = model1.fit(x_train, y_train
                      , epochs=5
                      , verbose=0
                      )

model1_score = print_accuracy(model1)
log_CM, fig = draw_CM(model1)
model1.summary()
```

- ì€ë‹‰ì¸µ ì—†ì´ ì¶œë ¥ì¦ì—ë§Œ í­ê·„ì¢…ë¥˜ 3ê°€ì§€ë§Œ ì§€ì •í•˜ê³ , ë‹¤ì¤‘ë¶„ë¥˜ í™œì„±í™”í•¨ìˆ˜ì¸ softmax ì§€ì •
- ìµœì†Œí•œì˜ í•™ìŠµì„ ìœ„í•˜ì—¬ epochsë¥¼ 5ë¡œ ì§€ì •
- ì…ë ¥ íŠ¹ì„± 7ê°œ, ì¶œë ¥ íƒ€ê²Ÿí´ë˜ìŠ¤ 3ê°œ, Total íŒŒë¼ë¯¸í„° 21ê°œ
- í‰ê°€ ì •í™•ë„ 53.6%...ğŸ˜­ğŸ˜¢ğŸ˜ (ë”¥ëŸ¬ë‹... ë²„ë ¤ì•¼ í•˜ë‚˜?)

```
# Train Accuracy : 0.436, Test Accuracy : 0.536
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_37 (Dense)            (None, 3)                 21        
                                                                 
=================================================================
Total params: 21
Trainable params: 21
Non-trainable params: 0
_________________________________________________________________
```

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/nn_base1.png){: .align-center width="60%"} 

<br>

### ê¸°ë³¸ ì¸ê³µì‹ ê²½ë§ : ì€ë‹‰ì¸µ 1ê°œ

- ì€ë‹‰ì¸µì„ í•˜ë‚˜ ë§Œë“¤ì–´ ë³´ì

```python
model1 = tf.keras.Sequential([
    Dense(100, activation='relu', kernel_initializer='he_uniform'),
    Dense(3, activation='softmax'),
    ])

model1.compile(metrics=['accuracy']
               , optimizer='adam'
               , loss='sparse_categorical_crossentropy'
               )

results1 = model1.fit(x_train, y_train
                      , epochs=5
                      , verbose=0
                      )

model1_score = print_accuracy(model1)
log_CM, fig = draw_CM(model1)
model1.summary()
```

- í•˜ë‚˜ì˜ ì€ë‹‰ì¸µì— ë…¸ë“œ 100ê°œ, í™œì„±í™”í•¨ìˆ˜ëŠ” ReLU, ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”ëŠ” 'he_uniform'ì„ ì§€ì •
- ì€ë‹‰ì¸µì´ ìƒê¸°ë©´ì„œ ì¶”ì •í•´ì•¼ í•  íŒŒë¼ë¯¸í„°ê°€ 1,003ê°œë¡œ ëŠ˜ì—ˆë‹¤.
- í‰ê°€ ì •í™•ë„ 76.8%!!

```
# Train Accuracy : 0.807, Test Accuracy : 0.768
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_38 (Dense)            (None, 100)               700       
                                                                 
 dense_39 (Dense)            (None, 3)                 303       
                                                                 
=================================================================
Total params: 1,003
Trainable params: 1,003
Non-trainable params: 0
```

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/nn_base2.png){: .align-center width="60%"} 

<br>

### ê¸°ë³¸ ì¸ê³µì‹ ê²½ë§ : ì€ë‹‰ì¸µ 2ê°œ

- ì¼ë°˜ì ìœ¼ë¡œ ë”¥ëŸ¬ë‹ì´ë¼ í•˜ë©´ ì€ë‹‰ì¸µì´ 2ê°œ ì´ìƒì„ ì˜ë¯¸í•œë‹¤.
- ì€ë‹‰ì¸µì„ 2ê°œ ì¶”ê°€í•´ë³´ì

```python
model1 = tf.keras.Sequential([
    Dense(100, activation='relu', kernel_initializer='he_uniform'),
    Dense(100, activation='relu', kernel_initializer='he_uniform'),
    Dense(3, activation='softmax'),
    ])

model1.compile(metrics=['accuracy']
               , optimizer='adam'
               , loss='sparse_categorical_crossentropy'
               )

results1 = model1.fit(x_train, y_train
                      , epochs=5
                      , verbose=0
                      )

model1_score = print_accuracy(model1)
log_CM, fig = draw_CM(model1)
model1.summary()
```

- ë˜‘ê°™ì€ ì€ë‹‰ì¸µì„ 2ê°œë¡œ ëŠ˜ë ¸ë‹¤
- í‰ê°€ ì •í™•ë„ 95.7%ğŸ‰

```
# Train Accuracy : 0.971, Test Accuracy : 0.957
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_40 (Dense)            (None, 100)               700       
                                                                 
 dense_41 (Dense)            (None, 100)               10100     
                                                                 
 dense_42 (Dense)            (None, 3)                 303       
                                                                 
=================================================================
Total params: 11,103
Trainable params: 11,103
Non-trainable params: 0
```

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/nn_base3.png){: .align-center width="60%"} 


- ì¸ê³µì‹ ê²½ë§ì˜ ì€ë‹‰ì¸µì´ 2ê°œ ì´ìƒìœ¼ë¡œ ëŠ˜ì–´ë‚˜ì§€ê¹ ì •í™•ë„ê°€ ê¸‰ ìƒìŠ¹í–ˆë‹¤


<br><br>


## ì¸ê³µì‹ ê²½ë§ ì‹¤í—˜

### ì‹¤í—˜1 : ì€ë‹‰ì¸µì˜ ìˆ˜ë¥¼ ëŠ˜ë¦¬ë©´ ì„±ëŠ¥ì´ ì˜¤ëŠ˜ê¹Œ?

- ì€ë‹‰ì¸µ 1ê°œ ~ 99ê°œ ê¹Œì§€ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì •í™•ë„ë¥¼ ë¹„êµí•´ë³´ì

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/test_hiddens.png){: .align-center width="60%"} 

- 2ê°œ ì´í›„ë¡œëŠ” ì„±ëŠ¥ì˜ í–¥ìƒì´ í¬ê²Œ ì—†ëŠ” ê²ƒ ê°™ë‹¤
- ì•ìœ¼ë¡œëŠ” íš¨ìœ¨ì„±ì„ ìœ„í•˜ì—¬ ì€ë‹‰ì¸µì€ 2ê°œë¡œ ê³ ì •í•  ê²ƒì´ë‹¤

<br>

### ì‹¤í—˜2 : ì€ë‹‰ì¸µì˜ ë…¸ë“œë¥¼ ëŠ˜ë¦¬ë©´ ì„±ëŠ¥ì´ ì˜¤ë¥¼ê¹Œ?

- ì€ë‹‰ì¸µì˜ ë…¸ë“œëŠ” ê°€ì¤‘ì¹˜ì™€ í¸í–¥ì˜ ê°€ì¤‘í•© ì—°ì‚°ì´ ì¼ì–´ë‚˜ëŠ” ë¶€ë¶„ì´ë‹¤.

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/test_node.png){: .align-center width="60%"} 

- ì€ë‹‰ì¸µì´ ì˜¤ë¥´ë©´ì„œ ì„±ëŠ¥ë„ ì˜¤ë¥´ê³ , ì„±ëŠ¥ì˜ ì•ˆì •ê°ë„ ì˜¤ë¥´ëŠ” ê²ƒ ê°™ë‹¤.
- ë…¸ë“œ 80 ì´í›„ë¡œëŠ” í° ì°¨ì´ê°€ ì—†ì–´ë³´ì¸ë‹¤.
- ì•ìœ¼ë¡œëŠ” ë…¸ë“œë¥¼ 100ì •ë„ë¡œ ê³ ì •í•  ê²ƒì´ë‹¤

<br>

### ì‹¤í—˜3 : ì€ë‹‰ì¸µì˜ ëª¨ì–‘ì€ ì„±ëŠ¥ê³¼ ì–´ë–¤ ìƒê´€ì´ ìˆì„ê¹Œ?

- 2ê°œ ì€ë‹‰ì¸µì˜ ë…¸ë“œ ë¹„ìœ¨ì„ 1:99 , 2:98 , 3:97 ...... 98:2 , 99:1 ë¡œ ë³€í™”ì‹œì¼œ ë³´ì

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/test_shape.png){: .align-center width="60%"} 

- 2ê°œ ì€ë‹‰ì¸µì˜ ë¹„ìœ¨ì´ í¬ê²Œ ì°¨ì´ë‚˜ëŠ” 1:99, 2:98 ... 98:2, 99:1 ì€ ì„±ëŠ¥ ì ìˆ˜ë„ ë‚®ê³ , ì•ˆì •ê°ë„ ë–¨ì–´ì§€ëŠ” ê²ƒ ê°™ë‹¤.
- ì€ë‹‰ì¸µì˜ ë¹„ìœ¨ì€ ë¹„ìŠ·í•œ ê²ƒì´ ì¢‹ê² ë‹¤.

<br>

### ìµœì  Layer ëª¨ë¸

- ì§€ê¸ˆê¹Œì§€ì˜ ì‹¤í—˜ì„ í† ëŒ€ë¡œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ì

```python
def get_model(nodes=100, lr=0.001):
    random.seed(rand_seed)
    model = tf.keras.Sequential([
                                Dense(nodes, activation='relu', kernel_initializer='he_uniform'),
                                Dense(nodes, activation='relu', kernel_initializer='he_uniform'),
                                Dense(3, activation='softmax'),
                                ])

    model.compile(metrics=['accuracy']
                  , optimizer=tf.keras.optimizers.Adam(learning_rate=lr)
                  , loss='sparse_categorical_crossentropy'
                  )
    
    return model
```

- ì•ìœ¼ë¡œì˜ ì‹¤í—˜ì€ ì•„ë˜ì˜ ëª¨ë¸ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì‹¤í–‰í•  ê²ƒì´ë‹¤

<br>

### ì‹¤í—˜4 : epochs

- epochëŠ” ì¸ê³µì‹ ê²½ë§ì´ ìˆœì „íŒŒì™€ ì—­ì „íŒŒë¥¼ í†µí•˜ì—¬ 1íšŒ í•™ìŠµì´ ì¼ì–´ë‚˜ëŠ” ê³¼ì •ì´ë‹¤.
- ì¸ê³µì‹ ê²½ë§ì—ì„œëŠ” ì—­ì „íŒŒë¥¼ í†µí•˜ì—¬ ëª¨ë¸ì˜ ì—…ë°ì´íŠ¸ê°€ ì¼ì–´ë‚˜ê¸° ë•Œë¬¸ì— epochê°€ ë§ì•„ì§€ë©´ ëª¨ë¸ì´ ì •êµí•´ì§ˆ ê°€ëŠ¥ì„±ì´ ìˆë‹¤.
- epochë¥¼ 1~30 ê¹Œì§€ ì¡°ì •í•˜ë©° ì •í™•ë„ë¥¼ í‰ê°€í•´ë³´ì

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/test_epoch.png){: .align-center width="60%"}  

<br>

### ì‹¤í—˜5 : batch_size

- ê²½ì‚¬í•˜ê°•ë²•ì„ í†µí•˜ì—¬ ì†ì‹¤í•¨ìˆ˜ë¥¼ ê³„ì‚°í•  ë•Œ ì „í†µì ìœ¼ë¡œëŠ” ëª¨ë“  ì…ë ¥ë°ì´í„°ì— ëŒ€í•˜ì—¬ ê³„ì‚°ì„ ìˆ˜í–‰í•˜ì˜€ë‹¤.
- ë°ì´í„°ê°€ ì»¤ì§€ë©´ì„œ ì‹œê°„ì´ ì˜¤ë˜ê±¸ë¦¬ê³  ë¹„íš¨ìœ¨ì„±ì´ ë†’ì•„ì ¸ í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²•, ê³§ ì¼ë¶€ë°ì´í„°ë¥¼ ë½‘ì•„ì„œ ì†ì‹¤í•¨ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì´ ìƒê²¨ë‚¬ë‹¤.
- batch_sizeë¥¼ ì§€ì •í•œë©´ ê·¸ë§Œí¼ ì…ë ¥ë°ì´í„°ë¥¼ ë½‘ì•„ ë¯¸ë‹ˆë°°ì¹˜(Mini-batch) ê²½ì‚¬í•˜ê°•ë²•ì„ ìˆ˜í–‰í•˜ê²Œ ëœë‹¤.
- ì´ë•Œ ì…ë ¥ë°ì´í„° ìˆ˜, batch_size, iterationì€ ë‹¤ìŒê³¼ ê°™ì€ ê´€ê³„ê°€ ì„±ë¦½ëœë‹¤.
- $Nobs. Data = batch\_size \times Iteration(by \; epoch)$
- ì‹¤í—˜ ê²°ê³¼ 80 ì´í•˜ê°€ ì ë‹¹í•œ ê²ƒ ê°™ë‹¤.

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/test_batch_size.png){: .align-center width="60%"}  


<br><br>


## í•™ìŠµë¥  ê³„íš

- ê°€ì¥ ì¤‘ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°€ìš´ë° í•˜ë‚˜ê°€ ë°”ë¡œ í•™ìŠµë¥ (Learning Rate)ì´ë‹¤.
- ì¸ê³µì‹ ê²½ë§ì—ì„œ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê³„ì‚°ìœ¼ë¡œ ìˆ˜í–‰ëœë‹¤.
- $\theta_{ i,j+1 } = \theta_{ i,j } - \eta { { \delta }\over{ \delta \theta_{ i,j } } }J(\theta)$
  - $\theta_{ i,j+1 }$ : ìƒˆë¡­ê²Œ ìƒì‹ ëœ ê°€ì¤‘ì¹˜
  - $\theta_{ i,j }$ : ê°±ì‹  ì „ ê°€ì¤‘ì¹˜
  - $\eta$ : í•™ìŠµë¥ 
  - ${ { \delta }\over{ \delta \theta_{ i,j } } }J(\theta)$ : í•´ë‹¹ ì§€ì ì—ì„œì˜ ê¸°ìš¸ê¸° 
- ê·¸ë˜ì„œ í•™ìŠµë¥ ì€ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ê³¼ì • ê°€ìš´ë° ê°€ì¤‘ì¹˜ì˜ ë³€í™”í­ì´ë¼ê³  ì´í•´í•  ìˆ˜ ìˆë‹¤.
- í•™ìŠµë¥ ì€ ì§ì—… ì§€ì •í•´ì¤„ ìˆ˜ë„ ìˆì§€ë§Œ ì£¼ë¡œ Step Decay, Cosine Decayì˜ ë‘ê°€ì§€ ë°©ì‹ì´ ìì£¼ ì‚¬ìš©ëœë‹¤.

### í•™ìŠµë¥  Step Decay

- í•™ìŠµë¥  Step DecayëŠ” ì‚¬ìš©ì í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ LearningRateScheduler() ë©”ì¨ë“œì— ë‹´ì•„ ì½œë°±ìœ¼ë¡œ í•™ìŠµê³¼ì •ìœ¼ë¡œ ë„˜ê²¨ì£¼ë©´ ëœë‹¤.

```python
# í•™ìŠµë¥  Step Decayë¥¼ ìœ„í•œ í•¨ìˆ˜
def step_decay(epoch):
    start = 0.2
    drop = 0.5
    epochs_drop = 3
    lr = start * (drop ** np.floor((epoch)/epochs_drop))
    return lr

lr_scheduler = LearningRateScheduler(step_decay, verbose=0)

model = get_model()

model_results = model.fit(x_train, y_train
                          , batch_size              = 16 # None
                          , epochs                  = 10 # 1
                          , verbose                 = 0 # 'auto'
                          , callbacks               = [lr_scheduler] # None
                          )

model_accuracy = print_accuracy(model, verbose=1)

# ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
fig, ax = plt.subplots( figsize=(5, 4) )
fig.suptitle('Step Decay', fontsize = 22, fontweight = 'bold', y = 1)

sns.lineplot(x=range(1,11), y=model_results.history['lr'], color='r', label='Learning Rate')

plt.xlabel('epoch', fontsize = 14)
plt.ylabel('Learning Rate', fontsize = 14)
plt.show()
```

- í•™ìŠµë¥ ì´ epochê°€ ì§„í–‰ë¨ì— ë”°ë¼ ë§Œë“  í•¨ìˆ˜ì— ë”°ë¼ì„œ ê°ì†Œí•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.
- Train Accuracy : 0.996, Test Accuracy : 0.986

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/step_decay.png){: .align-center width="60%"} 

<br>

### ### í•™ìŠµë¥  Cosine Decay





<br><br>


## ê³¼ì í•© ë°©ì§€


<br><br>


## í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

















<br>
<br>
<br>
<br>


<center>
<h1>ëê¹Œì§€ ì½ì–´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤ğŸ˜‰</h1>
</center>


<br>
<br>
<br>
<br>


<!-- 


{: .notice}
{: .notice--primary}
{: .notice--info}
{: .notice--warning}
{: .notice--danger}
{: .notice--success}

 -->





