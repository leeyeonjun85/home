---
title: "Penguins ì¸ê³µì‹ ê²½ë§"
excerpt: "Penguins ë°ì´í„°ë¡œ ì¸ê³µì‹ ê²½ë§ êµ¬ì„±í•˜ê¸°"

categories:
  - Dev Log

tags:
  - ê°œë°œì¼ì§€
  - ì½”ë”©
  - keras
  - Neural Network

use_math: true

header:
  teaser: /assets/images/aib/artificial-intelligence-3685928_1920.png

last_modified_at: 2023-02-21
---


<br><br>


![image]({{ site.url }}{{ site.baseurl }}/assets/images/etc/penguin_png.png){: .align-center width="70%"}  


<br><br>


<br><br>


# Penguins, ì¸ê³µì‹ ê²½ë§ êµ¬ì„±  


<br><br>


## ë„ì…  
>Penguins ë°ì´í„°ë¡œ ì¸ê³µì‹ ê²½ë§ ë§Œë“¤ê¸°  
ì¸ê³µì‹ ê²½ë§ì„ ê³µë¶€í•˜ëŠ”MNISTë¥¼ ìì£¼ ì‚¬ìš©í•˜ê³¤ í•˜ì§€ë§Œ, MNISTì˜ indexëŠ” 60,000ê°œë¡œ ì‚¬ì´ì¦ˆê°€ í¬ê¸° ë•Œë¬¸ì— í•™ìŠµì— ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦°ë‹¤.  
ê·¸ë˜ì„œ ë°ì´í„° ì‚¬ì´ì¦ˆê°€ ì‘ê³  ê·€ì—¬ìš´ Penguins ë°ì´í„°ë¡œ ì¸ê³µì‹ ê²½ë§ì„ ì—°ìŠµí•˜ì


<br><br>


## ë°ì´í„° ì „ì²˜ë¦¬  

### ë°ì´í„° ì½ì–´ì˜¤ê¸°  

```python
# Data Load
penguins = sns.load_dataset('penguins')
print(f"ğŸ¬ Rows, Columns : {penguins.shape}")
# ğŸ¬ Rows, Columns : (344, 7)
```

- ë°ì´í„°ëŠ” Seabornì—ì„œ ë¶ˆëŸ¬ì™”ë‹¤.
- ë°ì´í„°ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì€ [Seaborn ë§í¬ ì°¸ì¡°](https://github.com/allisonhorst/palmerpenguins) í•´ì£¼ì„¸ìš”

<br>

### íŠ¹ì„±ê³µí•™

- íŠ¹ë³„í•œ íŠ¹ì„±ê³µí•™ì€ í•˜ì§€ ì•ŠìŒ
- sexê°€ ê²°ì¸¡ì¸ ê²½ìš° 3ìœ¼ë¡œ ëŒ€ì²´
- ë‹¤ë¥¸ íŠ¹ì„±ì€ í‰ê· ìœ¼ë¡œ ëŒ€ì²´

```python
penguins_species = {
    'Adelie' : 0,
    'Gentoo' : 1,
    'Chinstrap' : 2,
}
penguins['species'] = penguins['species'].map(penguins_species)

penguins_island = {
    'Biscoe' : 0,
    'Dream' : 1,
    'Torgersen' : 2,
}
penguins['island'] = penguins['island'].map(penguins_island)

penguins_sex = {
    'Male' : 0,
    'Female' : 1,
    np.nan : 3,
}
penguins['sex'] = penguins['sex'].map(penguins_sex)

# NaN = Fill with Mean
for idx, col in enumerate(penguins.columns):
  penguins[col].fillna(penguins[col].mean(), inplace=True)
```

<br>

### ë°ì´í„° ë¶„í• 

```python
test_size = 0.2
x_train, x_test, y_train, y_test = train_test_split(penguins[features], penguins[target], test_size=test_size, random_state=rand_seed)
print(f'âœ¨Train Shape : {x_train.shape} / {y_train.shape}\nğŸ‰ Test Shape : {x_test.shape} / {y_test.shape}')
#âœ¨Train Shape : (275, 6) / (275, 1)
#ğŸ‰ Test Shape : (69, 6) / (69, 1)
```

<br>

### ì •ê·œí™”(Normalization)

```python
x_train = (x_train - np.min(x_train, axis='index')) / (np.max(x_train, axis='index') - np.min(x_train, axis='index'))
x_test  = ( x_test - np.min( x_test, axis='index')) / (np.max( x_test, axis='index') - np.min( x_test, axis='index'))
```


<br><br>


## íƒìƒ‰ì  ë°ì´í„° ë¶„ì„

### Seaborn ì˜ ë°ì´í„° ì†Œê°œë¡œ ëŒ€ì²´

![image](https://github.com/allisonhorst/palmerpenguins/raw/main/man/figures/culmen_depth.png){: .align-center width="60%"}  


![image](https://seaborn.pydata.org/_images/introduction_29_0.png){: .align-center width="80%"}  


<br><br>


## ëª¨ë¸ë§

### ê¸°ì¤€ëª¨ë¸ : Logistic Regression

- ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ëª¨ë¸ì„ ê¸°ì¤€ëª¨ë¸ë¡œ í•˜ì!

```python
log_model = LogisticRegression()
log_model.fit(x_train, y_train)
log_score = print_accuracy(log_model)
log_CM, fig = draw_CM(log_model)
# Train Accuracy : 0.978, Test Accuracy : 0.971
```

- ê¸°ë³¸ëª¨ë¸ ì •í™•ë„ê°€ ë¬´ë ¤ 97.1% ğŸ˜³ (í°ì¼ì´ë‹¤...)
- ë³´í†µì€ ê¸°ì¤€ëª¨ë¸ ì´ìƒì„ ëª©í‘œë¡œ í•˜ì§€ë§Œ ì˜¤ëŠ˜ì€ ê¸°ì¤€ëª¨ë¸ ë§Œí¼ì´ë¼ë„ ë‹¬ì„±í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ì

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/logit_cm.png){: .align-center width="60%"}  

<br>

### ê¸°ë³¸ ì¸ê³µì‹ ê²½ë§ : ì€ë‹‰ì¸µ 0ê°œ

- ê°€ì¥ ê¸°ë³¸ì ì¸ ì¸ê³µì‹ ê²½ë§ì„ ë§Œë“¤ì–´ë³´ì

```python
model1 = tf.keras.Sequential([
    Dense(3, activation='softmax'),
    ])

model1.compile(metrics=['accuracy']
               , optimizer='adam'
               , loss='sparse_categorical_crossentropy'
               )

results1 = model1.fit(x_train, y_train
                      , epochs=5
                      , verbose=0
                      )

model1_score = print_accuracy(model1)
log_CM, fig = draw_CM(model1)
model1.summary()
```

- ì€ë‹‰ì¸µ ì—†ì´ ì¶œë ¥ì¦ì—ë§Œ í­ê·„ì¢…ë¥˜ 3ê°€ì§€ë§Œ ì§€ì •í•˜ê³ , ë‹¤ì¤‘ë¶„ë¥˜ í™œì„±í™”í•¨ìˆ˜ì¸ softmax ì§€ì •
- ìµœì†Œí•œì˜ í•™ìŠµì„ ìœ„í•˜ì—¬ epochsë¥¼ 5ë¡œ ì§€ì •
- ì…ë ¥ íŠ¹ì„± 7ê°œ, ì¶œë ¥ íƒ€ê²Ÿí´ë˜ìŠ¤ 3ê°œ, Total íŒŒë¼ë¯¸í„° 21ê°œ
- í‰ê°€ ì •í™•ë„ 53.6%...ğŸ˜­ğŸ˜¢ğŸ˜ (ë”¥ëŸ¬ë‹... ë²„ë ¤ì•¼ í•˜ë‚˜?)

```
# Train Accuracy : 0.436, Test Accuracy : 0.536
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_37 (Dense)            (None, 3)                 21        
                                                                 
=================================================================
Total params: 21
Trainable params: 21
Non-trainable params: 0
_________________________________________________________________
```

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/nn_base1.png){: .align-center width="60%"} 

<br>

### ê¸°ë³¸ ì¸ê³µì‹ ê²½ë§ : ì€ë‹‰ì¸µ 1ê°œ

- ì€ë‹‰ì¸µì„ í•˜ë‚˜ ë§Œë“¤ì–´ ë³´ì

```python
model1 = tf.keras.Sequential([
    Dense(100, activation='relu', kernel_initializer='he_uniform'),
    Dense(3, activation='softmax'),
    ])

model1.compile(metrics=['accuracy']
               , optimizer='adam'
               , loss='sparse_categorical_crossentropy'
               )

results1 = model1.fit(x_train, y_train
                      , epochs=5
                      , verbose=0
                      )

model1_score = print_accuracy(model1)
log_CM, fig = draw_CM(model1)
model1.summary()
```

- í•˜ë‚˜ì˜ ì€ë‹‰ì¸µì— ë…¸ë“œ 100ê°œ, í™œì„±í™”í•¨ìˆ˜ëŠ” ReLU, ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”ëŠ” 'he_uniform'ì„ ì§€ì •
- ì€ë‹‰ì¸µì´ ìƒê¸°ë©´ì„œ ì¶”ì •í•´ì•¼ í•  íŒŒë¼ë¯¸í„°ê°€ 1,003ê°œë¡œ ëŠ˜ì—ˆë‹¤.
- í‰ê°€ ì •í™•ë„ 76.8%!!

```
# Train Accuracy : 0.807, Test Accuracy : 0.768
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_38 (Dense)            (None, 100)               700       
                                                                 
 dense_39 (Dense)            (None, 3)                 303       
                                                                 
=================================================================
Total params: 1,003
Trainable params: 1,003
Non-trainable params: 0
```

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/nn_base2.png){: .align-center width="60%"} 

<br>

### ê¸°ë³¸ ì¸ê³µì‹ ê²½ë§ : ì€ë‹‰ì¸µ 2ê°œ

- ì¼ë°˜ì ìœ¼ë¡œ ë”¥ëŸ¬ë‹ì´ë¼ í•˜ë©´ ì€ë‹‰ì¸µì´ 2ê°œ ì´ìƒì„ ì˜ë¯¸í•œë‹¤.
- ì€ë‹‰ì¸µì„ 2ê°œ ì¶”ê°€í•´ë³´ì

```python
model1 = tf.keras.Sequential([
    Dense(100, activation='relu', kernel_initializer='he_uniform'),
    Dense(100, activation='relu', kernel_initializer='he_uniform'),
    Dense(3, activation='softmax'),
    ])

model1.compile(metrics=['accuracy']
               , optimizer='adam'
               , loss='sparse_categorical_crossentropy'
               )

results1 = model1.fit(x_train, y_train
                      , epochs=5
                      , verbose=0
                      )

model1_score = print_accuracy(model1)
log_CM, fig = draw_CM(model1)
model1.summary()
```

- ë˜‘ê°™ì€ ì€ë‹‰ì¸µì„ 2ê°œë¡œ ëŠ˜ë ¸ë‹¤
- í‰ê°€ ì •í™•ë„ 95.7%ğŸ‰

```
# Train Accuracy : 0.971, Test Accuracy : 0.957
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_40 (Dense)            (None, 100)               700       
                                                                 
 dense_41 (Dense)            (None, 100)               10100     
                                                                 
 dense_42 (Dense)            (None, 3)                 303       
                                                                 
=================================================================
Total params: 11,103
Trainable params: 11,103
Non-trainable params: 0
```

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/nn_base3.png){: .align-center width="60%"} 


- ì¸ê³µì‹ ê²½ë§ì˜ ì€ë‹‰ì¸µì´ 2ê°œ ì´ìƒìœ¼ë¡œ ëŠ˜ì–´ë‚˜ì§€ê¹ ì •í™•ë„ê°€ ê¸‰ ìƒìŠ¹í–ˆë‹¤


<br><br>


## ì¸ê³µì‹ ê²½ë§ ì‹¤í—˜

### ì‹¤í—˜1 : ì€ë‹‰ì¸µì˜ ìˆ˜ë¥¼ ëŠ˜ë¦¬ë©´ ì„±ëŠ¥ì´ ì˜¤ëŠ˜ê¹Œ?

- ì€ë‹‰ì¸µ 1ê°œ ~ 99ê°œ ê¹Œì§€ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì •í™•ë„ë¥¼ ë¹„êµí•´ë³´ì

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/test_hiddens.png){: .align-center width="60%"} 

- 2ê°œ ì´í›„ë¡œëŠ” ì„±ëŠ¥ì˜ í–¥ìƒì´ í¬ê²Œ ì—†ëŠ” ê²ƒ ê°™ë‹¤
- ì•ìœ¼ë¡œëŠ” íš¨ìœ¨ì„±ì„ ìœ„í•˜ì—¬ ì€ë‹‰ì¸µì€ 2ê°œë¡œ ê³ ì •í•  ê²ƒì´ë‹¤

<br>

### ì‹¤í—˜2 : ì€ë‹‰ì¸µì˜ ë…¸ë“œë¥¼ ëŠ˜ë¦¬ë©´ ì„±ëŠ¥ì´ ì˜¤ë¥¼ê¹Œ?

- ì€ë‹‰ì¸µì˜ ë…¸ë“œëŠ” ê°€ì¤‘ì¹˜ì™€ í¸í–¥ì˜ ê°€ì¤‘í•© ì—°ì‚°ì´ ì¼ì–´ë‚˜ëŠ” ë¶€ë¶„ì´ë‹¤.

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/test_node.png){: .align-center width="60%"} 

- ì€ë‹‰ì¸µì´ ì˜¤ë¥´ë©´ì„œ ì„±ëŠ¥ë„ ì˜¤ë¥´ê³ , ì„±ëŠ¥ì˜ ì•ˆì •ê°ë„ ì˜¤ë¥´ëŠ” ê²ƒ ê°™ë‹¤.
- ë…¸ë“œ 80 ì´í›„ë¡œëŠ” í° ì°¨ì´ê°€ ì—†ì–´ë³´ì¸ë‹¤.
- ì•ìœ¼ë¡œëŠ” ë…¸ë“œë¥¼ 100ì •ë„ë¡œ ê³ ì •í•  ê²ƒì´ë‹¤

<br>

### ì‹¤í—˜3 : ì€ë‹‰ì¸µì˜ ëª¨ì–‘ì€ ì„±ëŠ¥ê³¼ ì–´ë–¤ ìƒê´€ì´ ìˆì„ê¹Œ?

- 2ê°œ ì€ë‹‰ì¸µì˜ ë…¸ë“œ ë¹„ìœ¨ì„ 1:99 , 2:98 , 3:97 ...... 98:2 , 99:1 ë¡œ ë³€í™”ì‹œì¼œ ë³´ì

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/test_shape.png){: .align-center width="60%"} 

- 2ê°œ ì€ë‹‰ì¸µì˜ ë¹„ìœ¨ì´ í¬ê²Œ ì°¨ì´ë‚˜ëŠ” 1:99, 2:98 ... 98:2, 99:1 ì€ ì„±ëŠ¥ ì ìˆ˜ë„ ë‚®ê³ , ì•ˆì •ê°ë„ ë–¨ì–´ì§€ëŠ” ê²ƒ ê°™ë‹¤.
- ì€ë‹‰ì¸µì˜ ë¹„ìœ¨ì€ ë¹„ìŠ·í•œ ê²ƒì´ ì¢‹ê² ë‹¤.

<br>

### ìµœì  Layer ëª¨ë¸

- ì§€ê¸ˆê¹Œì§€ì˜ ì‹¤í—˜ì„ í† ëŒ€ë¡œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ì

```python
def get_model(nodes=100, lr=0.001):
    random.seed(rand_seed)
    model = tf.keras.Sequential([
                                Dense(nodes, activation='relu', kernel_initializer='he_uniform'),
                                Dense(nodes, activation='relu', kernel_initializer='he_uniform'),
                                Dense(3, activation='softmax'),
                                ])

    model.compile(metrics=['accuracy']
                  , optimizer=tf.keras.optimizers.Adam(learning_rate=lr)
                  , loss='sparse_categorical_crossentropy'
                  )
    
    return model
```

- ì•ìœ¼ë¡œì˜ ì‹¤í—˜ì€ ì•„ë˜ì˜ ëª¨ë¸ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì‹¤í–‰í•  ê²ƒì´ë‹¤

<br>

### ì‹¤í—˜4 : epochs

- epochëŠ” ì¸ê³µì‹ ê²½ë§ì´ ìˆœì „íŒŒì™€ ì—­ì „íŒŒë¥¼ í†µí•˜ì—¬ 1íšŒ í•™ìŠµì´ ì¼ì–´ë‚˜ëŠ” ê³¼ì •ì´ë‹¤.
- ì¸ê³µì‹ ê²½ë§ì—ì„œëŠ” ì—­ì „íŒŒë¥¼ í†µí•˜ì—¬ ëª¨ë¸ì˜ ì—…ë°ì´íŠ¸ê°€ ì¼ì–´ë‚˜ê¸° ë•Œë¬¸ì— epochê°€ ë§ì•„ì§€ë©´ ëª¨ë¸ì´ ì •êµí•´ì§ˆ ê°€ëŠ¥ì„±ì´ ìˆë‹¤.
- epochë¥¼ 1~30 ê¹Œì§€ ì¡°ì •í•˜ë©° ì •í™•ë„ë¥¼ í‰ê°€í•´ë³´ì

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/test_epoch.png){: .align-center width="60%"}  

<br>

### ì‹¤í—˜5 : batch_size

- ê²½ì‚¬í•˜ê°•ë²•ì„ í†µí•˜ì—¬ ì†ì‹¤í•¨ìˆ˜ë¥¼ ê³„ì‚°í•  ë•Œ ì „í†µì ìœ¼ë¡œëŠ” ëª¨ë“  ì…ë ¥ë°ì´í„°ì— ëŒ€í•˜ì—¬ ê³„ì‚°ì„ ìˆ˜í–‰í•˜ì˜€ë‹¤.
- ë°ì´í„°ê°€ ì»¤ì§€ë©´ì„œ ì‹œê°„ì´ ì˜¤ë˜ê±¸ë¦¬ê³  ë¹„íš¨ìœ¨ì„±ì´ ë†’ì•„ì ¸ í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²•, ê³§ ì¼ë¶€ë°ì´í„°ë¥¼ ë½‘ì•„ì„œ ì†ì‹¤í•¨ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì´ ìƒê²¨ë‚¬ë‹¤.
- batch_sizeë¥¼ ì§€ì •í•œë©´ ê·¸ë§Œí¼ ì…ë ¥ë°ì´í„°ë¥¼ ë½‘ì•„ ë¯¸ë‹ˆë°°ì¹˜(Mini-batch) ê²½ì‚¬í•˜ê°•ë²•ì„ ìˆ˜í–‰í•˜ê²Œ ëœë‹¤.
- ì´ë•Œ ì…ë ¥ë°ì´í„° ìˆ˜, batch_size, iterationì€ ë‹¤ìŒê³¼ ê°™ì€ ê´€ê³„ê°€ ì„±ë¦½ëœë‹¤.
- $Nobs. Data = batch\_size \times Iteration(by \; epoch)$
- ì‹¤í—˜ ê²°ê³¼ 80 ì´í•˜ê°€ ì ë‹¹í•œ ê²ƒ ê°™ë‹¤.

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/test_batch_size.png){: .align-center width="60%"}  


<br><br>


## í•™ìŠµë¥  ê³„íš

- ê°€ì¥ ì¤‘ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°€ìš´ë° í•˜ë‚˜ê°€ ë°”ë¡œ í•™ìŠµë¥ (Learning Rate)ì´ë‹¤.
- ì¸ê³µì‹ ê²½ë§ì—ì„œ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê³„ì‚°ìœ¼ë¡œ ìˆ˜í–‰ëœë‹¤.
- $\theta_{ i,j+1 } = \theta_{ i,j } - \eta { { \delta }\over{ \delta \theta_{ i,j } } }J(\theta)$
  - $\theta_{ i,j+1 }$ : ìƒˆë¡­ê²Œ ìƒì‹ ëœ ê°€ì¤‘ì¹˜
  - $\theta_{ i,j }$ : ê°±ì‹  ì „ ê°€ì¤‘ì¹˜
  - $\eta$ : í•™ìŠµë¥ 
  - ${ { \delta }\over{ \delta \theta_{ i,j } } }J(\theta)$ : í•´ë‹¹ ì§€ì ì—ì„œì˜ ê¸°ìš¸ê¸° 
- ê·¸ë˜ì„œ í•™ìŠµë¥ ì€ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ê³¼ì • ê°€ìš´ë° ê°€ì¤‘ì¹˜ì˜ ë³€í™”í­ì´ë¼ê³  ì´í•´í•  ìˆ˜ ìˆë‹¤.
- í•™ìŠµë¥ ì€ ì§ì—… ì§€ì •í•´ì¤„ ìˆ˜ë„ ìˆì§€ë§Œ ì£¼ë¡œ Step Decay, Cosine Decayì˜ ë‘ê°€ì§€ ë°©ì‹ì´ ìì£¼ ì‚¬ìš©ëœë‹¤.

### í•™ìŠµë¥  Step Decay

- í•™ìŠµë¥  Step DecayëŠ” ì‚¬ìš©ì í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ LearningRateScheduler() ë©”ì¨ë“œì— ë‹´ì•„ ì½œë°±ìœ¼ë¡œ í•™ìŠµê³¼ì •ìœ¼ë¡œ ë„˜ê²¨ì£¼ë©´ ëœë‹¤.

```python
# í•™ìŠµë¥  Step Decayë¥¼ ìœ„í•œ í•¨ìˆ˜
def step_decay(epoch):
    start = 0.2
    drop = 0.5
    epochs_drop = 3
    lr = start * (drop ** np.floor((epoch)/epochs_drop))
    return lr

lr_scheduler = LearningRateScheduler(step_decay, verbose=0)

model = get_model()

model_results = model.fit(x_train, y_train
                          , batch_size              = 16 # None
                          , epochs                  = 10 # 1
                          , verbose                 = 0 # 'auto'
                          , callbacks               = [lr_scheduler] # None
                          )

model_accuracy = print_accuracy(model, verbose=1)

# ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
fig, ax = plt.subplots( figsize=(5, 4) )
fig.suptitle('Step Decay', fontsize = 22, fontweight = 'bold', y = 1)

sns.lineplot(x=range(1,11), y=model_results.history['lr'], color='r', label='Learning Rate')

plt.xlabel('epoch', fontsize = 14)
plt.ylabel('Learning Rate', fontsize = 14)
plt.show()
```

- í•™ìŠµë¥ ì´ epochê°€ ì§„í–‰ë¨ì— ë”°ë¼ ë§Œë“  í•¨ìˆ˜ì— ë”°ë¼ì„œ ê°ì†Œí•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.
- Train Accuracy : 0.996, Test Accuracy : 0.986

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/penguins/step_decay.png){: .align-center width="60%"} 

<br>

### ### í•™ìŠµë¥  Cosine Decay





<br><br>


## ê³¼ì í•© ë°©ì§€


<br><br>


## í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹


```python
# ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤
(train_images, train_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()
print(f"{train_images.shape},{train_labels.shape},{test_images.shape},{test_labels.shape}")
```

```
(60000, 28, 28),(60000,),(10000, 28, 28),(10000,)
```

- Fashion MNIST ë°ì´í„°ëŠ” MNISTì™€ í•¨ê»˜ ë”¥ëŸ¬ë‹ì˜ 'Hellow, World!'ì™€ ê°™ì€ ë°ì´í„°ì´ë‹¤.
- keras.datasets.fashion_mnist.load_data() ë©”ì¨ë“œëŠ” ë„˜íŒŒì´ íŠœí”Œì„ ë°˜í™˜í•œë‹¤.
- í•™ìŠµë°ì´í„°ëŠ” 60,000ê°œ, í‰ê°€ë°ì´í„°ëŠ” 10,000ê°œì´ë‹¤.
- 28í”½ì…€ì˜ í‘/ë°± íŠ¹ì„±ì„ ë‹´ê³  ìˆë‹¤.

<br>

### ë°ì´í„° ì •ê·œí™”
- ë°ì´í„°ë¥¼ 255ë¡œ ë‚˜ëˆ„ì–´ 0~1ì‚¬ì´ì˜ ìˆ˜ë¡œ ì •ê·œí™”(Normalization)í•œë‹¤.
- ì •ê·œí™” í•˜ëŠ” ì´ìœ ?
  - 0~1 ì‚¬ì´ë¡œ ë§ì¶”ì–´ ê³„ì‚° ê°’ì´ ë„ˆë¬´ ì»¤ì§€ëŠ” ê²ƒì„ ë°©ì§€
  - Local Minimunì— ë¹ ì§€ëŠ” ê²ƒì„ ë°©ì§€(í•™ìŠµ ì†ë„ í–¥ìƒ)

- í›ˆë ¨ë°ì´í„° ì¸ë±ìŠ¤20,000ë²ˆ ë°ì´í„°ì˜ ì •ê·œí™” í•˜ê¸° ì´ì „ ê°’ ì‚´í´ë³´ê¸°

```python
train_images[attention_train][10]
```

```
array([  0,   0,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,
       160, 255, 217, 255,  94,   0,   0,   0,   1,   4,   0,   0,   0,
        65,  38], dtype=uint8)
```

- ì •ê·œí™” ì‹¤í–‰ $x - x_{min} \over x_{max} - x_{min}$  
  - ìµœì†Œê°’ì´ 0ì´ê¸° ë•Œë¬¸ì— ìµœëŒ€ê°’(255)ë¡œ ë‚˜ëˆ„ê¸°ë§Œ í•˜ì˜€ë‹¤

```python
train_images = train_images / 255.0
test_images = test_images / 255.0
```

```
array([0.        , 0.        , 0.        , 0.        , 0.        ,
       0.        , 0.        , 0.        , 0.00784314, 0.        ,
       0.        , 0.        , 0.        , 0.62745098, 1.        ,
       0.85098039, 1.        , 0.36862745, 0.        , 0.        ,
       0.        , 0.00392157, 0.01568627, 0.        , 0.        ,
       0.        , 0.25490196, 0.14901961])
```

<br>

### ë°ì´í„° ì‚´í´ë³´ê¸°

- íƒ€ê²Ÿ ë¼ë²¨ í™•ì¸í•˜ê¸°

```python
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
print(pd.DataFrame({'Label':class_names}).to_markdown())
```

|    | Label       |
|---:|:------------|
|  0 | T-shirt/top |
|  1 | Trouser     |
|  2 | Pullover    |
|  3 | Dress       |
|  4 | Coat        |
|  5 | Sandal      |
|  6 | Shirt       |
|  7 | Sneaker     |
|  8 | Bag         |
|  9 | Ankle boot  |

<br>

- í›ˆë ¨ë°ì´í„° ì¸ë±ìŠ¤20,000ë²ˆ ë°ì´í„°ë¥¼ ì‹œê°í™” í•´ë³´ì

```python
plt.imshow(train_images[attention_train], cmap='gray_r')
plt.colorbar(shrink = .4)
plt.grid(False)
plt.show()
```

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/f_mnist/f_mnist_train20000.png){: .align-center width="60%"}  

<br>

- í›ˆë ¨ë°ì´í„° 25ê°œ ë°ì´í„°ë¥¼ ì‹œê°í™” í•´ë³´ì

```python
for i, val in enumerate(range(attention_train-12,attention_train+13)):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[val], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[val]])
plt.show()
```

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/f_mnist/f_mnist_review.png){: .align-center width="80%"}  


<br><br>


## ëª¨ë¸ë§

### ëª¨ë¸ êµ¬ì„±í•˜ê¸°

```python
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
```

- 28í”½ì…€ í‘ë°± ë°ì´í„°ì´ê¸° ë•Œë¬¸ì— ì…ë ¥ì¸µì—ëŠ” (28, 28)ë¡œ ì…ë ¥í•œë‹¤.
- ì€ë‹‰ì¸µì˜ ë…¸ë“œëŠ” 128ê°œ, í™œì„±í™”í•¨ìˆ˜ëŠ” reluë¥¼ ì‚¬ìš©í–ˆë‹¤.
- ì¶œë ¥ì¸µì€ 10ê°œ ë…¸ë“œì™€ softmax í™œì„±í™”í•¨ìˆ˜ë¥¼ ì§€ì •í•˜ì˜€ë‹¤.

<br>

### ëª¨ë¸ í•™ìŠµí•˜ê³  í‰ê°€í•˜ê¸°

```python
model.fit(train_images, train_labels, epochs=10)
test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)
print('\nTest accuracy:', test_acc)
```

```
Epoch 1/10
1875/1875 [==============================] - 7s 3ms/step - loss: 0.4966 - accuracy: 0.8267
Epoch 2/10
1875/1875 [==============================] - 5s 3ms/step - loss: 0.3765 - accuracy: 0.8638
Epoch 3/10
1875/1875 [==============================] - 6s 3ms/step - loss: 0.3392 - accuracy: 0.8759
Epoch 4/10
1875/1875 [==============================] - 5s 3ms/step - loss: 0.3156 - accuracy: 0.8855
Epoch 5/10
1875/1875 [==============================] - 5s 3ms/step - loss: 0.2979 - accuracy: 0.8905
Epoch 6/10
1875/1875 [==============================] - 6s 3ms/step - loss: 0.2817 - accuracy: 0.8958
Epoch 7/10
1875/1875 [==============================] - 5s 3ms/step - loss: 0.2686 - accuracy: 0.9003
Epoch 8/10
1875/1875 [==============================] - 6s 3ms/step - loss: 0.2586 - accuracy: 0.9033
Epoch 9/10
1875/1875 [==============================] - 5s 3ms/step - loss: 0.2477 - accuracy: 0.9072
Epoch 10/10
1875/1875 [==============================] - 6s 3ms/step - loss: 0.2401 - accuracy: 0.9104
313/313 - 0s - loss: 0.3328 - accuracy: 0.8863 - 488ms/epoch - 2ms/step

Test accuracy: 0.8863000273704529
```

- ìˆœì „íŒŒì™€ ì—­ì „íŒŒë¥¼ 10ë²ˆ ë°˜ë³µí•˜ì—¬ ì‹ ê²½ë§ì„ í•™ìŠµí•œë‹¤.
- í‰ê°€ë°ì´í„°ì— ëŒ€í•˜ì—¬ ì •í™•ë„ë¥¼ ì‚°ì¶œ
- í‰ê°€ì •í™•ë„ 88.6%

<br>

### ëª¨ë¸ í™•ì¸í•˜ê¸°

- ëª¨ë¸ ì¶”ì •  

```python
probability_model = tf.keras.Sequential([model, keras.layers.Softmax()])
predictions = probability_model.predict(test_images)
```

#### í‰ê°€ ì¸ë±ìŠ¤ 2,000ë²ˆ, ëª¨ë¸ ì¶”ì •  

- ëª¨ë¸ì€ 8ë²ˆ(Bag)ì´ë¼ ì˜ˆì¸¡
- ì¶”ì •ì´ ë§ëŠ”ì§€ í™•ì¸í•´ ë³´ì

```python
i = test_1
plt.figure(figsize=(6,3))
plt.subplot(1,2,1)
plot_image(i, predictions[i], test_labels, test_images)
plt.subplot(1,2,2)
plot_value_array(i, predictions[i],  test_labels)
plt.xticks(range(10), class_names, rotation=90)
plt.show()
```

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/f_mnist/f_mnist_test1.png){: .align-center width="70%"}  

- ë§ì•˜ë‹¤~!ğŸ˜„

#### í‰ê°€ ì¸ë±ìŠ¤ 800ë²ˆ, ëª¨ë¸ ì¶”ì •  

- ëª¨ë¸ì€ 9ë²ˆ(Ankle boot)ì´ë¼ ì˜ˆì¸¡
- ì¶”ì •ì´ ë§ëŠ”ì§€ í™•ì¸í•´ ë³´ì

```python
i = test_2
plt.subplot(1,2,1)
plot_image(i, predictions[i], test_labels, test_images)
plt.subplot(1,2,2)
plot_value_array(i, predictions[i],  test_labels)
plt.xticks(range(10), class_names, rotation=90)
plt.show()
```

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/f_mnist/f_mnist_test2.png){: .align-center width="70%"}  

- í‹€ë ¸ë‹¤...ğŸ˜¥

#### í‰ê°€ë°ì´í„° 15ê°œ ì¶”ì •  

```python
num_rows = 5
num_cols = 3
num_images = num_rows*num_cols

fig, ax = plt.subplots( figsize=(2*2*num_cols, 2*num_rows) )

for i in range(num_images):
  plt.subplot(num_rows, 2*num_cols, 2*i+1)
  plot_image(i, predictions[i], test_labels, test_images)
  plt.subplot(num_rows, 2*num_cols, 2*i+2)
  plot_value_array(i, predictions[i], test_labels)
plt.tight_layout()
plt.show()
```

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/f_mnist/f_mnist_test15s.png){: .align-center width="70%"} 

- ëª¨ë¸ì´ ëŒ€ë¶€ë¶„ ë§í˜”ëŠ”ë°(íŒŒë€ìƒ‰), í‹€ë¦°ê²ƒ(ë¹¨ê°„ìƒ‰)ë„ ìˆë‹¤


#### í˜¼ëˆí–‰ë ¬(Confusion Matrix)  

![image]({{ site.url }}{{ site.baseurl }}/assets/images/coding/f_mnist/f_mnist_cm.png){: .align-center width="70%"}  




<br>
<br>
<br>
<br>


<center>
<h1>ëê¹Œì§€ ì½ì–´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤ğŸ˜‰</h1>
</center>


<br>
<br>
<br>
<br>


<!-- 


{: .notice}
{: .notice--primary}
{: .notice--info}
{: .notice--warning}
{: .notice--danger}
{: .notice--success}

 -->





